{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Classification using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0a46e266481>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importing required libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "No. of Images in training set (55000, 784)\n",
      "No. of Labels in training set (55000, 10)\n",
      "No. of Images in test set (10000, 784)\n",
      "No. of Labels in test set (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading the Dataset\n",
    "mnist = input_data.read_data_sets(\"data/mnist\",\n",
    "                                 one_hot = True)\n",
    "print(\"No. of Images in training set {}\" .format(mnist.train.images.shape))\n",
    "print(\"No. of Labels in training set {}\" .format(mnist.train.labels.shape))\n",
    "\n",
    "print(\"No. of Images in test set {}\" .format(mnist.test.images.shape))\n",
    "print(\"No. of Labels in test set {}\" .format(mnist.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for First Image:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEs1JREFUeJzt3XuUnHV9x/H3h1yRBAJGQgyECMUqWg26oIDVUCpCjkrUgkTgxFM1yMXjrVZNVdBzQOQULBZBQ0kFK7dTCReFCsULYrltLIVguAkhxCwJuVASwGSTfPvHPGsnYeeZ2Zln5pns7/M6Z8/MPt/n8s1kP/M8M89NEYGZpWenshsws3I4/GaJcvjNEuXwmyXK4TdLlMNvliiHv40k/VLSx5uc9kRJtxbdU51lTpW0QdKITi7XyuHwt0jSUkkvZaFZKelfJY0b4jymSQpJIweGRcSPIuKo4jt+Wc8DP6+OiGURMS4itjQxz49KurPOOE2/GVrxHP5ivC8ixgFvAQ4GvlJyP414Xxb0gZ8VeSOrwn8vw4j/MwsUEX8AbgHeuH1N0k6SviLpKUmrJF0habesfEf2+Fy2Fj50+zVptmXwSUmPSVon6buSlNVGSDpf0mpJT0o6Y/stiUZsvwWSranPlvQb4EVgv6yvJyStz5Z1oqTXA98DDs36f66BZc2QtFzS32evR5+kWZJmSnpU0lpJ86rGP0TSXZKey8a9SNLoqvpRkh6R9L+SLpb0q+qtDEl/K2lJ9tr9TNK+Q3lthiOHv0CS9gFmAv89SPmj2c8RwH7AOOCirPbO7HFCtha+q8Yi3ktly+LNwPHAe7LhnwCOAaZT2fqY1cq/YzsnA3OB8cCzwHeAYyJiPHAYcH9ELAE+CdyV9T+hwXnvBYwFpgBfAy4FTgLeCvwl8DVJ+2XjbgE+C0wEDgWOBE4DkDQR+Hfgy8ArgUey3sjqs4B5wAeBVwG/Bq4a6gsx3Dj8xbg+W9vdCfwKOGeQcU4ELoiIJyJiA5U/1BOGuHY+NyKei4hlwC+ohB0qbwQXRsTyiFgHnNtoz9nP9Tnj/SAiHoqIzcBmYCvwRkk7R0RfRDw0hP631w+cHRH9wNVUgn1hRKzP5vsQ8CaAiFgUEXdHxOaIWAp8H3hXNp+ZwEMRcV3W53eAZ6qWcwrwzYhYktXPAaanvvZ3+IsxKyImRMS+EXFaRLw0yDivBp6q+v0pYCQwaQjLqf6DfpHK1sPAvJ+uqlU/r9fzhIjI21L407wi4gXgw1TW8n2SfirpdY21Pqg1VV8uDrxmK6vqL5H9GyW9VtJPJD0j6XkqAZ6YjbfNvz8qZ6str5rPvsCFA292wFpAVLY4kuXwd84KKn+EA6ZSWZOuBFo9tbIP2Lvq931anF+1bXqLiJ9FxLuBycDDVDbVXzZeG1ySLe+AiNiVyma8sto2//7su5Dq1+Np4JSqN7sJEbFzRPxXm3vuag5/51wFfFbSa7JdgecA12Sboc9S2ZzeL28GOa4FPi1piqQJwBcL6Xg7kiZJer+kXYCNwAYqn8Wh8ia2d/WXcAUbDzwPbMi2Nk6tqv0U+IvsC8ORwOlUvk8Y8D3gy5LekP07dpN0XJv63GE4/J2zAPghlW/2nwT+CHwKICJeBM4GfpNtmr59iPO+FLgVeIDKl403U9mqGPL++jp2Aj5PZStmLZXP3KdltZ9T+Yz+jKTVBS8X4O+AjwDrqfx7rxkoRMRq4DjgPGANcCDQS+UNiohYCHwLuDr7yLCYyhekSZMv5jH8SDoG+F5EJPmFVnY8wnLgxIj4Rdn9dCuv+YcBSTtn+8dHSpoCnAksLLuvTpL0HkkTJI3h/78PuLvktrqawz88CPg6sI7KZv8SKvvNU3Io8HtgNfA+KnszBtvrYhlv9pslymt+s0QN6djvVo3WmBjLLp1cpFlS/sgLbIqNqj9mi+GXdDRwITAC+JeIyD2sdCy78DYd2coizSzHPXF7w+M2vdmvygUfvktlf+mBwGxJBzY7PzPrrFY+8x8CPJ6dqLKJyokZxxbTlpm1Wyvhn8K2J5AsZ5ATJSTNldQrqbe/csCVmXWBVsI/2JcKL9tvGBHzI6InInpGMaaFxZlZkVoJ/3K2PXtsbyrHfJvZDqCV8N8HHJCdpTYaOAG4sZi2zKzdmt7VFxGbJZ0B/IzKrr4FLV7Vxcw6qKX9/BFxM5XTR81sB+PDe80S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miWrpFt6SlwHpgC7A5InqKaMrM2q+l8GeOiIjVBczHzDrIm/1miWo1/AHcKmmRpLmDjSBprqReSb39bGxxcWZWlFY3+w+PiBWS9gRuk/RwRNxRPUJEzAfmA+yqPaLF5ZlZQVpa80fEiuxxFbAQOKSIpsys/ZoOv6RdJI0feA4cBSwuqjEza69WNvsnAQslDcznyoj4j0K6MrO2azr8EfEE8OYCezGzDvKuPrNEOfxmiXL4zRLl8JslyuE3S1QRJ/ZYyfo+d1jNmuocUzl2Tf4I616XP/3ku7bkz/+me/NnYKXxmt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S9Sw2c+/6vTa+7oBnntTf2594VEXFdlOR71+9H1NT/vH2Jxb322nnXPrq05+Ibe+4ju1/8QueObdudOuOX7X3Prmp5fn1i2f1/xmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIU0bmb6OyqPeJtOrLp6R+99OCatYdnXpw77RiNanq5Vo6Tls7Ira/7SJ3jAJYuK7CbHcM9cTvPx1o1Mq7X/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zonao8/kvOeKKmrV6+/G/teaA3PqqTeOb6qkI1y16a2596k0N7bYtxfIj89cf5828smbtQ+Oez53236b9Mrd+0pUzcuvrPrx3zZqvBdDAml/SAkmrJC2uGraHpNskPZY97t7eNs2saI1s9v8AOHq7YV8Cbo+IA4Dbs9/NbAdSN/wRcQewdrvBxwKXZ88vB2YV3JeZtVmzX/hNiog+gOxxz1ojSporqVdSbz8bm1ycmRWt7d/2R8T8iOiJiJ5RjGn34sysQc2Gf6WkyQDZ46riWjKzTmg2/DcCc7Lnc4AbimnHzDql7vn8kq4CZgATgZXAmcD1wLXAVGAZcFxEbP+l4Mu0ej6/3vqGmrXV0/PP7d7z+kdy61vW1G3fmrDTm15Xs/beq3+TO+3pE55uadl/ftmpNWvTvnpXS/PuVkM5n7/uQT4RMbtGqfkUm1npfHivWaIcfrNEOfxmiXL4zRLl8Jslaoe6dLcNL2s+cWhuvffrl7Q0/0UbN9WszXvNIS3Nu1v50t1mVpfDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRK1Q92i23Y8y+cdVrO29aD1bV32pBG1z+ff/Ff5t0Uf+fNFRbfTdbzmN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5ev2DwMj95tWs/b4xybnTnvxCfML7mZbM8b216yNUHnrnt/3b8itn7bvOzrUSbEKvW6/pAWSVklaXDXsLEl/kHR/9jOzlYbNrPMaeev9AXD0IMO/HRHTs5+bi23LzNqtbvgj4g5gbQd6MbMOauVD1xmSHsg+FuxeayRJcyX1SurtZ2MLizOzIjUb/kuA/YHpQB9wfq0RI2J+RPRERM8oxjS5ODMrWlPhj4iVEbElIrYClwLD85anZsNYU+GXVL3/6APA4lrjmll3qns+v6SrgBnAREnLgTOBGZKmAwEsBU5pY4/D3obj3pZbf/Yt+e/R3/jg1TVrJ4xf11RPxenO48j++j8/k1t/Lb0d6qQ8dcMfEbMHGXxZG3oxsw7qzrdlM2s7h98sUQ6/WaIcfrNEOfxmifKluwugg96QW59wUV9u/eZpl+TW23nq6/UvjMutL35p75bm/5PzZtSsjdiYfzr5nG/clFufu9uKZloCYPQzo5qedrjwmt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5T38zfoqa/XvtX0V0+4JnfaE8evya0v2/xibv3hTTWvkgbAp676eM3aK/ryr+I8+Zerc+tbfvdobr2e3bi76Wkf+/KkOjPP38//ZM7luafdkH/p7hR4zW+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcr7+Rs04eBVNWv19uMf+bv359b7/3mv3PrON9ybW5/GXbn1PFuanrJ1W991UG591oR6F4nOX3et3Tq6dvHeB+vMe/jzmt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S1Qjt+jeB7gC2AvYCsyPiAsl7QFcA0yjcpvu4yOi7PtBt80rP1b7/O8/+9ypudPu/4X8/fAjWdZUTzu6da8dm1s/fGxr66a5i0+qWZtIa9cpGA4aeXU3A5+PiNcDbwdOl3Qg8CXg9og4ALg9+93MdhB1wx8RfRHx2+z5emAJMAU4Frg8G+1yYFa7mjSz4g1pu0rSNOAg4B5gUkT0QeUNAtiz6ObMrH0aDr+kccCPgc9ExPNDmG6upF5Jvf1sbKZHM2uDhsIvaRSV4P8oIq7LBq+UNDmrTwYGPfMlIuZHRE9E9IxiTBE9m1kB6oZfkoDLgCURcUFV6UZgTvZ8DnBD8e2ZWbs0ckrv4cDJwIOS7s+GzQPOBa6V9DFgGXBce1rsDpv7nqlZ2/8LtWtW25qDN7c0/ZJN+Zc8H3/xbi3Nf7irG/6IuBOodfH3I4ttx8w6xUf4mSXK4TdLlMNvliiH3yxRDr9Zohx+s0T50t3WVu9ZXPtI8IUTvltn6pxLbwNzHpqTW9/9lvvqzD9tXvObJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zonyfn5rq7/Z9YGatVfsNC532kf7X8itv+KiCU31ZBVe85slyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmifJ+fmvJqtMOy61PGlH7nPon+2vf9hxg9jlfyK1PvCX/1ueWz2t+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRdffzS9oHuALYC9gKzI+ICyWdBXwCeDYbdV5E3NyuRq0cGjMmt/6hT/48t75+66aatZn3npo77dTvez9+OzVykM9m4PMR8VtJ44FFkm7Lat+OiH9sX3tm1i51wx8RfUBf9ny9pCXAlHY3ZmbtNaTP/JKmAQcB92SDzpD0gKQFknavMc1cSb2SevvZ2FKzZlachsMvaRzwY+AzEfE8cAmwPzCdypbB+YNNFxHzI6InInpGkf/50cw6p6HwSxpFJfg/iojrACJiZURsiYitwKXAIe1r08yKVjf8kgRcBiyJiAuqhk+uGu0DwOLi2zOzdmnk2/7DgZOBByXdnw2bB8yWNB0IYClwSls6tHJtjdzyD286Ird+y//MqFmbeu3dzXRkBWnk2/47AQ1S8j59sx2Yj/AzS5TDb5Yoh98sUQ6/WaIcfrNEOfxmifKluy1X9Nc+JRdg2j/4tNsdldf8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miFJF/vnahC5OeBZ6qGjQRWN2xBoamW3vr1r7AvTWryN72jYhXNTJiR8P/soVLvRHRU1oDObq1t27tC9xbs8rqzZv9Zoly+M0SVXb455e8/Dzd2lu39gXurVml9FbqZ34zK0/Za34zK4nDb5aoUsIv6WhJj0h6XNKXyuihFklLJT0o6X5JvSX3skDSKkmLq4btIek2SY9lj4PeI7Gk3s6S9Ifstbtf0sySettH0i8kLZH0kKRPZ8NLfe1y+irldev4Z35JI4BHgXcDy4H7gNkR8buONlKDpKVAT0SUfkCIpHcCG4ArIuKN2bDzgLURcW72xrl7RHyxS3o7C9hQ9m3bs7tJTa6+rTwwC/goJb52OX0dTwmvWxlr/kOAxyPiiYjYBFwNHFtCH10vIu4A1m43+Fjg8uz55VT+eDquRm9dISL6IuK32fP1wMBt5Ut97XL6KkUZ4Z8CPF31+3JKfAEGEcCtkhZJmlt2M4OYFBF9UPljAvYsuZ/t1b1teydtd1v5rnntmrndfdHKCP9gt/7qpv2Nh0fEW4BjgNOzzVtrTEO3be+UQW4r3xWavd190coI/3Jgn6rf9wZWlNDHoCJiRfa4ClhI9916fOXAHZKzx1Ul9/Mn3XTb9sFuK08XvHbddLv7MsJ/H3CApNdIGg2cANxYQh8vI2mX7IsYJO0CHEX33Xr8RmBO9nwOcEOJvWyjW27bXuu28pT82nXb7e5LOcIv25XxT8AIYEFEnN3xJgYhaT8qa3uoXNb8yjJ7k3QVMIPKKZ8rgTOB64FrganAMuC4iOj4F281eptBZdP1T7dtH/iM3eHe3gH8GngQ2JoNnkfl83Vpr11OX7Mp4XXz4b1mifIRfmaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zov4PBe2u80P39v8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image\n",
    "img1 = mnist.train.images[0].reshape(28,28)\n",
    "plt.title(\"Ploting First Image\")\n",
    "plt.imshow(img1)\n",
    "print(\"Label for First Image: \", mnist.train.labels[0]) # Due to One-Hot coding, label is 1 if the image is for 7 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-3381f5626cdc>:41: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the number of Neurons in each layer\n",
    "num_input = 784 # Image Size\n",
    "num_hidden1 = 512\n",
    "num_hidden2 = 256\n",
    "num_hidden3 = 128\n",
    "num_output = 10 # Number ranges from 0 to 9\n",
    "\n",
    "# Defining the placeholder for Input and Output\n",
    "with tf.name_scope(\"input\"):\n",
    "    X = tf.placeholder(\"float\",[None,num_input])\n",
    "with tf.name_scope(\"output\"):\n",
    "    Y = tf.placeholder(\"float\",[None,num_output])\n",
    "    \n",
    "# Defining the placeholder for Weights and Biases\n",
    "with tf.name_scope(\"weights\"):\n",
    "    weights = {\"W1\":tf.Variable(tf.truncated_normal([num_input,num_hidden1],stddev = 0.1), name = \"weight_1\"),\n",
    "              \"W2\":tf.Variable(tf.truncated_normal([num_hidden1,num_hidden2],stddev = 0.1), name = \"weight_2\"),\n",
    "              \"W3\":tf.Variable(tf.truncated_normal([num_hidden2,num_hidden3],stddev = 0.1), name = \"weight_3\"),\n",
    "              \"W4\":tf.Variable(tf.truncated_normal([num_hidden3,num_output],stddev = 0.1), name = \"weight_4\")}\n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    biases = {\"b1\":tf.Variable(tf.constant(0.1, shape = [num_hidden1]), name = \"bias_1\"),\n",
    "             \"b2\":tf.Variable(tf.constant(0.1,shape = [num_hidden2]), name = \"bias_2\"),\n",
    "             \"b3\":tf.Variable(tf.constant(0.1,shape = [num_hidden3]), name = \"bias_3\"),\n",
    "             \"b4\":tf.Variable(tf.constant(0.1,shape = [num_output]), name = \"bias_4\")}\n",
    "    \n",
    "# Defining placeholder for Forward Propagation\n",
    "# ReLU Function for first three layer and Sigmoid Function for Output layer\n",
    "with tf.name_scope(\"Model\"):\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        layer_1 = tf.nn.relu(tf.add(tf.matmul(X, weights['W1']), biases['b1']))\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['W2']), biases['b2']))\n",
    "    with tf.name_scope(\"layer3\"):\n",
    "        layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['W3']), biases['b3']))\n",
    "    with tf.name_scope(\"output_layer\"):\n",
    "        y_hat = tf.nn.sigmoid(tf.matmul(layer_3, weights['W4']) + biases['b4'])\n",
    "        \n",
    "# Defining the placeholder for Loss and Backpropagation\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = y_hat))\n",
    "#     loss = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_hat), reduction_indices=[1]))\n",
    "#     y_hat_softmax = tf.nn.softmax(y_hat)\n",
    "#     loss = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_hat_softmax), [1]))\n",
    "    \n",
    "# Defind the Optimizer to optimize the weights in order to reduce the Loss\n",
    "# Use Adam Gradient Descent flavour\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Compute Accuracy\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    predicted_digit = tf.argmax(y_hat,1)\n",
    "    actual_digit = tf.argmax(Y,1)\n",
    "    correct_pred = tf.equal(predicted_digit,actual_digit)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    \n",
    "# Creating Summary\n",
    "tf.summary.scalar(\"Accuracy\",accuracy)\n",
    "tf.summary.scalar(\"Loss\",loss)\n",
    "merge_summary = tf.summary.merge_all()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 2.326857566833496, Accuracy: 0.125\n",
      "Iteration: 100, Loss: 1.7414755821228027, Accuracy: 0.859375\n",
      "Iteration: 200, Loss: 1.6284838914871216, Accuracy: 0.890625\n",
      "Iteration: 300, Loss: 1.5774109363555908, Accuracy: 0.90625\n",
      "Iteration: 400, Loss: 1.5845731496810913, Accuracy: 0.90625\n",
      "Iteration: 500, Loss: 1.5581016540527344, Accuracy: 0.921875\n",
      "Iteration: 600, Loss: 1.5599150657653809, Accuracy: 0.9296875\n",
      "Iteration: 700, Loss: 1.5465670824050903, Accuracy: 0.921875\n",
      "Iteration: 800, Loss: 1.5236587524414062, Accuracy: 0.953125\n",
      "Iteration: 900, Loss: 1.5376360416412354, Accuracy: 0.9140625\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "init = tf.global_variables_initializer()\n",
    "learning_rate = 1e-4\n",
    "num_iteration = 1000\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    summary_writer = tf.summary.FileWriter('./graphs',graph = sess.graph)\n",
    "    for i in range(num_iteration):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer,feed_dict = {X:batch_x, Y:batch_y})\n",
    "        # Print Loss and Accuracy for every 100th iteration\n",
    "        if i % 100 == 0:\n",
    "            batch_loss,batch_accuracy,summary = sess.run([loss,accuracy,merge_summary], feed_dict = {X:batch_x, Y:batch_y})\n",
    "            # Store all summary\n",
    "            summary_writer.add_summary(summary,i)\n",
    "            print('Iteration: {}, Loss: {}, Accuracy: {}'.format(i,batch_loss,batch_accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
